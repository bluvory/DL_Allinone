{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import FailtogetConv_error as fe\n",
    "fe.fail_to_get_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels.txt', 'test', 'train']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../dataset/cifar/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = glob('../dataset/cifar/train/*.png')[:1000]\n",
    "test_paths = glob('../dataset/cifar/test/*.png')[:1000]\n",
    "\n",
    "len(train_paths), len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(path):\n",
    "    return path.split('_')[-1].replace('.png', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [get_class_name(path) for path in train_paths]\n",
    "class_names = np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    fname = tf.strings.split(path, '_')[-1]\n",
    "    lbl_name = tf.strings.regex_replace(fname, '.png', '')\n",
    "    onehot = tf.cast(lbl_name == class_names, tf.uint8)\n",
    "    return tf.argmax(onehot)  # 이번에는 onehot이 아닌 label 번호로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_label(path):\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    \n",
    "    image = tf.cast(image, tf.float32) / 255.  # rescale\n",
    "    \n",
    "    label = get_label(path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, label):\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(image_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20210128-080359'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join('logs', datetime.now().strftime('%Y%m%d-%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    histogram_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-613182b907532f6a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-613182b907532f6a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8115;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --port 8115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-a96bac30de81>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      " 1/31 [..............................] - ETA: 0s - loss: 2.3169 - accuracy: 0.1250WARNING:tensorflow:From /home/jovyan/.venv/tf2.3.0-keras2.4.0-py3.7-cuda10.1/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/31 [>.............................] - ETA: 0s - loss: 2.2826 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0075s vs `on_train_batch_end` time: 0.0517s). Check your callbacks.\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 2.3001 - accuracy: 0.1178 - val_loss: 2.2746 - val_accuracy: 0.1129\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 2.2454 - accuracy: 0.1291 - val_loss: 2.2398 - val_accuracy: 0.1613\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 2.1877 - accuracy: 0.1601 - val_loss: 2.0891 - val_accuracy: 0.2087\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.1489 - accuracy: 0.1994 - val_loss: 2.0072 - val_accuracy: 0.2419\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 2.0120 - accuracy: 0.2399 - val_loss: 1.9856 - val_accuracy: 0.2944\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.9996 - accuracy: 0.2405 - val_loss: 2.0626 - val_accuracy: 0.2379\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.9300 - accuracy: 0.2810 - val_loss: 1.8742 - val_accuracy: 0.2893\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.8824 - accuracy: 0.2975 - val_loss: 1.9813 - val_accuracy: 0.2560\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 1.9104 - accuracy: 0.2645 - val_loss: 1.8952 - val_accuracy: 0.2893\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.8214 - accuracy: 0.3044 - val_loss: 1.8337 - val_accuracy: 0.3065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f49806bf050>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(test_paths) // batch_size\n",
    "\n",
    "model.fit_generator(train_dataset,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=validation_steps,\n",
    "                    epochs=num_epochs,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Callbacks\n",
    "https://www.tensorflow.org/tensorboard/image_summaries#setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)  # Loss 계산\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)  # 모델의 trainable_variable을 하여금 loss를 통해 기울기를 얻음\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))  # 구한 최적화된 값을 variable에 적용\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join('logs',  datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.create_file_writer(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for step, (images, labels) in enumerate(train_dataset):            \n",
    "        train_step(images, labels)\n",
    "\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image('input_image', images, step=step+(step*epoch))\n",
    "        tf.summary.scalar('train_loss', train_loss.result(), step=step+(step*epoch))\n",
    "        tf.summary.scalar('train_accuracy', train_accuracy.result(), step=step+(step*epoch))\n",
    "\n",
    "    for test_images, test_labels in test_dataset:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print (template.format(epoch+1,\n",
    "                           train_loss.result(),\n",
    "                           train_accuracy.result()*100,\n",
    "                           test_loss.result(),\n",
    "                           test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.001*math.exp(0.1*(10-epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.9571 - accuracy: 0.4442 - val_loss: 1.9584 - val_accuracy: 0.3538\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 1.5288 - accuracy: 0.4990 - val_loss: 1.7868 - val_accuracy: 0.3841\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.2533 - accuracy: 0.5692 - val_loss: 1.8944 - val_accuracy: 0.3861\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 1.2759 - accuracy: 0.5897 - val_loss: 1.9213 - val_accuracy: 0.4103\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 1.1681 - accuracy: 0.5971 - val_loss: 1.8779 - val_accuracy: 0.4103\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.0517 - accuracy: 0.6483 - val_loss: 1.9377 - val_accuracy: 0.4294\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.0452 - accuracy: 0.6498 - val_loss: 1.9447 - val_accuracy: 0.4254\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 1.0237 - accuracy: 0.6684 - val_loss: 1.9074 - val_accuracy: 0.4143\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.9584 - accuracy: 0.6724 - val_loss: 2.0308 - val_accuracy: 0.4153\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.9449 - accuracy: 0.6829 - val_loss: 2.0123 - val_accuracy: 0.4234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4aa93844d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(test_paths) // batch_size\n",
    "\n",
    "model.fit_generator(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[learning_rate_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(save_path,\n",
    "                                                monitor='val_acc',\n",
    "                                                verbose=1,\n",
    "                                                save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.7529 - accuracy: 0.7389WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.7636 - accuracy: 0.7386 - val_loss: 2.0739 - val_accuracy: 0.4143\n",
      "Epoch 2/10\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.7765 - accuracy: 0.7169WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7742 - accuracy: 0.7200 - val_loss: 2.0110 - val_accuracy: 0.4234\n",
      "Epoch 3/10\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.7695 - accuracy: 0.7426WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7536 - accuracy: 0.7448 - val_loss: 2.1231 - val_accuracy: 0.4264\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.7322 - accuracy: 0.7593WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7322 - accuracy: 0.7593 - val_loss: 2.1140 - val_accuracy: 0.4315\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.7469 - accuracy: 0.7583WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7469 - accuracy: 0.7583 - val_loss: 2.0072 - val_accuracy: 0.4395\n",
      "Epoch 6/10\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.7008 - accuracy: 0.7532WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7033 - accuracy: 0.7541 - val_loss: 2.0002 - val_accuracy: 0.4355\n",
      "Epoch 7/10\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.7544 - accuracy: 0.7405WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7610 - accuracy: 0.7440 - val_loss: 2.0355 - val_accuracy: 0.4597\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.7758WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6367 - accuracy: 0.7758 - val_loss: 2.1354 - val_accuracy: 0.4496\n",
      "Epoch 9/10\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6773 - accuracy: 0.7689WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6732 - accuracy: 0.7680 - val_loss: 1.9219 - val_accuracy: 0.4456\n",
      "Epoch 10/10\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.6713 - accuracy: 0.7676WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6597 - accuracy: 0.7727 - val_loss: 1.9895 - val_accuracy: 0.4365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4aa6ce5510>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(test_paths) // batch_size\n",
    "\n",
    "model.fit_generator(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.3.0-keras2.4.0-py3.7-cuda10.1",
   "language": "python",
   "name": "tf2.3.0-keras2.4.0-py3.7-cuda10.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
